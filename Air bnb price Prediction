# -*- coding: utf-8 -*-
"""
Created on Fri May 15 20:12:35 2020

@author: sasim
"""

import pandas as pd
import matplotlib.pyplot as plt
import math
import numpy as np
import seaborn as sb

dataset = pd.read_csv("'''\\airbnb-price-prediction\\train.csv")

dataset.info()

null_value = dataset.isnull().sum().sort_values(ascending=False)
null_value = dataset.isnull().sum().sort_values(ascending=False)
dataset.describe()
dataset.head()

##Data Preprocessing
dataset=dataset.drop("host_response_rate",axis=1)
dataset=dataset.drop("review_scores_rating",axis=1)
dataset=dataset.drop("first_review",axis=1)
dataset=dataset.drop("last_review",axis=1)
dataset=dataset.drop("thumbnail_url",axis=1)
dataset=dataset.drop("zipcode",axis=1)
dataset=dataset.drop("host_since",axis=1)
dataset=dataset.drop("latitude",axis=1)
dataset=dataset.drop("longitude",axis=1)
dataset=dataset.drop("cleaning_fee",axis=1)
dataset=dataset.drop("amenities",axis=1)
dataset=dataset.drop("description",axis=1)
dataset=dataset.drop("name",axis=1)
dataset=dataset.drop("neighbourhood",axis=1)

dataset.bathrooms=dataset["bathrooms"].fillna(dataset["bathrooms"].mean())
dataset.host_identity_verified=dataset["host_identity_verified"].fillna(dataset["host_identity_verified"].mode()[0])
dataset.host_has_profile_pic=dataset["host_has_profile_pic"].fillna(dataset["host_has_profile_pic"].mode()[0])
dataset.beds=dataset["beds"].fillna(dataset["beds"].mean())
dataset.bedrooms=dataset["bedrooms"].fillna(dataset["bedrooms"].mean())
dataset.head()
dataset.info()

#splitting x&y
x= dataset
x=x.drop('log_price',axis=1)
y=dataset.loc[:,['log_price']]


x=x.reshape(-1,1)

###get dummies
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
labelencoder=LabelEncoder()
label=dataset.loc[:,["property_type","room_type","bed_type","cancellation_policy","city",
                     "host_has_profile_pic","host_identity_verified","instant_bookable"]]
new_label=label.apply(labelencoder.fit_transform)
ohe=OneHotEncoder(categorical_features='label')
#x_new=ohe.fit_transform(label)
#x_train=ohe.fit_transform(x_train)
new_ohe=pd.get_dummies(dataset.loc[:,["property_type","room_type","bed_type","cancellation_policy","city",
                     "host_has_profile_pic","host_identity_verified","instant_bookable"]])
new_ohe.info()

new1_ohe=new_ohe.drop(['property_type_Apartment','bed_type_Airbed','cancellation_policy_flexible','city_Boston','host_has_profile_pic_f','host_identity_verified_f','instant_bookable_f'],1)
x=x.drop(["property_type","room_type","bed_type","cancellation_policy","city",
                     "host_has_profile_pic","host_identity_verified","instant_bookable"],1)
x=pd.concat([x,new1_ohe], axis=1)

x.info()
##vif
def vif_calc(x):
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    x['intercept']=1
    vif=pd.DataFrame()
    vif['variables']=x.columns
    vif['vif'] = [variance_inflation_factor(x.values,i) for i in range (0,x.shape[1])]
    return(vif)
vif = vif_calc(x)

x=x.drop(['room_type_Entire home/apt'],1)
x=x.drop(['city_NYC'],1)
x=x.drop(['bed_type_Real Bed'],1)
x=x.drop(['accommodates'],1)

x=x.drop(['intercept'],1)


#Train test split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    x,y,test_size=1/3,random_state=0)

y_test = y_test.drop(['index'],1)


#Multiple Linear Regression
from sklearn.linear_model import LinearRegression
regression=LinearRegression()

regression.fit(x_train,y_train)
regression.coef_
regression.intercept_
####y_pred
y_pred=regression.predict(x_test)

from math import sqrt
from sklearn.metrics import mean_squared_error as mse
print(sqrt(mse(y_test,y_pred))) 

# check score
print('Train Score: ', regression.score(x_train,y_train))
print('Test Score: ', regression.score(x_test,y_pred))


'''We have train set accuracy of 0.541508927435149 and test set accuracy of 1.0'''

##Decision tree
from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor()
tree.fit(x_train,y_train)

####y_pred
y_pred_tree=tree.predict(x_test)

print(sqrt(mse(y_test,y_pred_tree))) 



# check score
print('Train Score: ', tree.score(x_train,y_train))
print('Test Score: ', tree.score(x_test,y_pred_tree))

'''We have train set accuracy of 1.0 and test set accuracy of 1.0'''

##Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
rf_reg = RandomForestRegressor(n_estimators=100)
rf_reg.fit(x_train,y_train)
y_pred_ran = rf_reg.predict(x_test)

print(sqrt(mse(y_test,y_pred_ran)))

# check score
print('Train Score: ', rf_reg.score(x_train,y_train))
print('Test Score: ', rf_reg.score(x_test,y_pred_ran))


'''We have train set accuracy of 0.9351817175108958 and test set accuracy of 1.0'''
 
##Gradient boosting
from sklearn.ensemble import GradientBoostingRegressor
grad = GradientBoostingRegressor()
grad.fit(x_train,y_train)

####y_pred
y_pred_grad=grad.predict(x_test)

print(sqrt(mse(y_test,y_pred_grad))) 

# check score
print('Train Score: ', grad.score(x_train,y_train))
print('Test Score: ', grad.score(x_test,y_pred_grad))


'''We have train set accuracy of 0.5863712843579777 and test set accuracy of 1.0'''

# XG Boosting
import xgboost
from xgboost import XGBRegressor
xboost = XGBRegressor()
xboost.fit(x_train,y_train)
####y_pred
y_pred_boost=xboost.predict(x_test)

print(sqrt(mse(y_test,y_pred_boost))) 

# check score
print('Train Score: ', xboost.score(x_train,y_train))
print('Test Score: ', xboost.score(x_test,y_pred_boost))


'''We have train set accuracy of 0.6535062127252593 and test set accuracy of 1.0'''



####Regularization
    ####Lasso&Ridge
    
###Cross Validation
from sklearn.linear_model import LinearRegression
lin = LinearRegression()
from sklearn.model_selection import cross_val_score
mse=cross_accuracy=cross_val_score(lin,x_train,y_train,cv=5,scoring='r2')

mse = np.mean(mse)
print(mse)

#ridge&lasso
#Ridge
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

ridge = Ridge()

parameter={'alpha':[0,1e-10,1e-15,1,2,3,10,50,100]}

ridge_grid=GridSearchCV(ridge,
                         param_grid=parameter,
                         scoring='r2',
                         cv=5)

ridge_grid.fit(x_train,y_train)
y_pred_ridge=ridge_grid.predict(x_test)

ridge_grid.best_score_
ridge_grid.best_params_

##Lasso
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV

lasso = Lasso()

parameter={'alpha':[0,1e-10,1e-15,1,2,3,10,50,100]}

lasso_grid=GridSearchCV(lasso,
                         param_grid=parameter,
                         scoring='r2',
                         cv=5)

lasso_grid.fit(x_train,y_train)

y_pred_lasso=lasso_grid.predict(x_test)
lasso_grid.best_score_
lasso_grid.best_params_


##PCA
from sklearn.preprocessing import StandardScaler
scale=StandardScaler()
PCA=scale.fit_transform(x)
PCA=pd.DataFrame(PCA)
dataset.columns
PCA.columns=x.columns
new_PCA=pd.concat([x,PCA],axis=1)
#train test split
from sklearn.model_selection import train_test_split
x_train_pca, x_test_pca,y_train_pca,y_test_pca = train_test_split(new_PCA,y,test_size = 0.25, random_state = 100)


from sklearn.decomposition import PCA
pca=PCA()

x_train_pca=pca.fit_transform(x_train_pca)
x_test_pca=pca.transform(x_test_pca)
explained_ratio=pca.explained_variance_ratio_


np.cumsum(explained_ratio)
####
from sklearn.decomposition import PCA
pca=PCA(n_components=10)

x_train_pca=pca.fit_transform(x_train_pca)
x_test_pca=pca.transform(x_test_pca)
explained_ratio=pca.explained_variance_ratio_

import numpy as np
np.cumsum(explained_ratio)


from sklearn.linear_model import LinearRegression
regression=LinearRegression()
regression.fit(x_train_pca,y_train_pca)
regression.coef_
regression.intercept_

y_pred_pca=regression.predict(x_test_pca)

from sklearn.metrics import r2_score
r2_score(y_test_pca, y_pred_pca)

# check score
print('Train Score: ', regression.score(x_train_pca,y_train_pca))
print('Test Score: ', regression.score(x_test_pca,y_pred_pca))
'''We have train set accuracy of 0.33781126055345057 and test set accuracy of 1.0'''




##Ordinary least square
##Backward elimination
import statsmodels.api as sm
x['intercept']=1
x_OLS = x
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["bed_type_Pull-out Sofa"],axis=1)

#iteration 1
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Chalet"],axis=1)

#iteration 2
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["id"],axis=1)

#iteration 3
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Townhouse"],axis=1)

#iteration 4
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Cave"],axis=1)

#iteration 5
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Casa particular"],axis=1)

#iteration 6
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Lighthouse"],axis=1)

#iteration 7
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Treehouse"],axis=1)

#iteration 8
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Bungalow"],axis=1)

#iteration 9
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Cabin"],axis=1)

#iteration 10
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["cancellation_policy_strict"],axis=1)

#iteration 11
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Yurt"],axis=1)

#iteration 12
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Island"],axis=1)

#iteration 13
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Parking Space"],axis=1)

#iteration 14
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Train"],axis=1)

#iteration 15
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x_OLS=x_OLS.drop(["property_type_Vacation home"],axis=1)

#iteration 16
reg_OLS = sm.OLS(y,x_OLS).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)


reg_OLS.rsquared_adj
reg_OLS.rsquared


x_OLS=x_OLS.drop(['intercept'],axis=1)
from sklearn.model_selection import train_test_split
x_train_ols, x_test_ols,y_train_ols,y_test_ols = train_test_split(x_OLS,y,test_size = 0.25, random_state = 100)

from sklearn.linear_model import LinearRegression
regression=LinearRegression()
regression.fit(x_train_ols,y_train_ols)
regression.coef_
regression.intercept_


y_pred_ols=regression.predict(x_test_ols)


from sklearn.metrics import r2_score

r2_ols = r2_score(y_test_ols, y_pred_ols)
print(r2_ols)
plt.scatter(y_test_ols,y_pred_ols)

x_train_ols.info()



